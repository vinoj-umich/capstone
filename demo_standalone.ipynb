{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f969e91-fa8c-448d-b137-7760a2fe9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Import custom modules\n",
    "from common.chroma_db import ChromaDBSearcher\n",
    "from common.chat_model import ModelQA\n",
    "from common.cache import ModelCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e480a2e-ad58-49cc-827d-201a67d9723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinoj/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/vinoj/.local/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1002: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/vinoj/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7d64030f3c464b96d0f9dd0aa6474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Initialize model cache and load model\n",
    "model_cache = ModelCache()\n",
    "\n",
    "# Model selection\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'  # Example model ID for the chatbot\n",
    "\n",
    "# Check if the model is already cached to avoid reloading it\n",
    "model_qa = model_cache.get(model_id)\n",
    "if model_qa is None:\n",
    "    # If the model is not cached, initialize the ChromaDB searcher and load the model\n",
    "    searcher = ChromaDBSearcher()  # Initialize the ChromaDB searcher for document retrieval\n",
    "    model_qa = ModelQA(model_id=model_id, searcher=searcher)  # Create a new ModelQA instance\n",
    "    model_cache.set(model_id, model_qa)  # Cache the model for future use\n",
    "\n",
    "# Load the tokenizer and language model only once for efficiency\n",
    "tokenizer, llm_model = model_qa.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208e4133-6fbb-4b9e-b250-3c8426c421af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Function to display chat history in a readable format\n",
    "def display_chat_history(chat_history):\n",
    "    \"\"\"\n",
    "    Display the chat history in the notebook with user and bot messages.\n",
    "\n",
    "    Args:\n",
    "    - chat_history (list): List of chat exchanges, each containing a user message and a bot response.\n",
    "    \"\"\"\n",
    "    for chat in chat_history:\n",
    "        # Sanitize and clean user and bot messages to remove unwanted HTML or special characters\n",
    "        user_message = re.sub(r'<.*?>', '', chat[\"user\"]).replace(\"~\", \"\")\n",
    "        bot_message = re.sub(r'<.*?>', '', chat[\"bot\"]).replace(\"~\", \"\")\n",
    "        \n",
    "        # Display user and bot messages in the notebook\n",
    "        print(f\"User: {user_message}\")\n",
    "        print(f\"Bot: {bot_message}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4646a1-7a10-4e65-912a-f2720b0d0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize chat history list\n",
    "chat_history = []\n",
    "\n",
    "# 5. Available document sources (this could represent manuals, documents, etc.)\n",
    "document_sources = [\n",
    "    \"Fraggles_X500_2024_FMS\",\n",
    "    \"Fraggles_X700_2022_HCM\"   \n",
    "    # Add more sources as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95dc2362-be53-419b-85e3-32cd7f33f4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a Car Model, Make & Year from the list below:\n",
      "1. Fraggles_X500_2024_FMS\n",
      "2. Fraggles_X700_2022_HCM\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the document source:  1\n"
     ]
    }
   ],
   "source": [
    "# 6. Ask the user to select a document source from the available list\n",
    "print(\"Select a Car Model, Make & Year from the list below:\")\n",
    "for i, doc in enumerate(document_sources):\n",
    "    print(f\"{i + 1}. {doc}\")\n",
    "\n",
    "# Get user input for selecting a document source\n",
    "document_source_index = int(input(\"Enter the number corresponding to the document source: \")) - 1\n",
    "document_source = document_sources[document_source_index]  # Get the selected document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7b155f-2c73-49b0-a510-ef21a59be9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your query here (or type 'exit' to quit):  contact number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating response...\n",
      "User: contact number\n",
      "Bot:  Using the following context items, please answer the user query directly.\n",
      "                        Extract and incorporate relevant information from the context, but do not mention the context or how you arrived at your answer.\n",
      "                        Provide a clear, concise, and explanatory answer.\n",
      "                        \n",
      "                        Now use the following context items to answer the user query:\n",
      "                        - ['FragglesX500FMS 2024          1                                      Contact Information  If you require assistance or clariﬁcation on policies or  procedures, please contact the  customer relationship center. United States:      Fraggles Cars Auto  Customer Relationship Center  PO Box 12345  Brookﬁeld, NY 12345  Phone: 1-800-555-1234  Website: www.FragglesAutoSupport.com', 'FragglesX500FMS 2024          95  accept the decision, Fraggles must comply within 30  days. For assistance, contact AutoLine at 1-800-123-4567, or  write to:  Fraggles AutoLine  123 Elm Street, Suite 500  Anytown, USA 12345  For additional information, visit our website or call our  Customer Service Center at 7‗❹66‗❶❶❶‗❺❹❸❷.    Mediation and Arbitration in Canada: CAMVAP Program  If you are in Canada and have unresolved issues despite  efforts by Fraggles of Canada and an authorized dealer, you  can access the Canadian Motor Vehicle Arbitration Plan  (CAMVAP). Beneﬁts of CAMVAP:  •  No Cost to You: The program is free and avoids  lengthy legal proceedings. •  Impartial and Fast: Third-party arbitrators hear the  case and issue binding decisions for both parties. Contact CAMVAP at 7‗❹66‗86❸‗6❷❹❶ or visit  their website at www.camvap.ca.']\n",
      "\n",
      "User Query: What is the contact information for Fraggles AutoLine in the United States?\n",
      "\n",
      "Answer: If you require assistance or clarification on policies or procedures, please contact the customer relationship center. United States: Fraggles Cars Auto Customer Relationship Center PO Box 12345 Brookfield, NY 12345 Phone: 1-800-555-1234 Website: www.FragglesAutoSupport.com.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your query here (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 7. Main loop for chatting with the bot\n",
    "while True:\n",
    "    # Prompt user for a query\n",
    "    query = input(\"\\nEnter your query here (or type 'exit' to quit): \")\n",
    "    \n",
    "    if query.lower() == 'exit':\n",
    "        # Exit the chat loop if user types 'exit'\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Process the query and get the response from the model\n",
    "    print(\"\\nGenerating response...\")\n",
    "    answer = model_qa.ask(document_source, query)  # Model will use the document source to generate the response\n",
    "    \n",
    "    # Display the bot's response\n",
    "    \n",
    "    #print(f\"Bot: {answer}\")\n",
    "    \n",
    "    # Append the user query and bot response to the chat history\n",
    "    chat_history.append({\"user\": query, \"bot\": answer})\n",
    "\n",
    "    # Optionally, display the full chat history\n",
    "    display_chat_history(chat_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
